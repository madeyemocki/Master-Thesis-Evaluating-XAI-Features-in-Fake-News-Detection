# Master Thesis

### Evaluating XAI Features in Fake News Detection

Fake news has become a widespread problem that affects everyone in one way or an-
other. Fortunately, some machine-based methods and models can detect Fake News.
The challenge now is that humans cannot always understand how these models arrive
at their calculations; this is where eXplainable Artificial Intelligence (XAI) comes in.
This work evaluates XAI features in the context of Fake News detection. The study
examines the effects of various XAI features on trust, usefulness, understandability, and
opinions about AI and compares the responses of journalists and laypeople. The study
aims to identify effective XAI features that can improve the accuracy and trustworthi-
ness of machine-based models for detecting fake news. The study uses a mixed-methods
approach with open-ended questions, Likert scales, and comparative analysis to collect
quantitative and qualitative data. The results show that XAI features have a signifi-
cant impact on local understandability, trust, and usefulness. But the specific features
used do not have a significant impact. Including natural language explanations in the
system only increases the usefulness of the explanations. However, participantsâ€™ overall
opinion of AI is not significantly affected by XAI features

### Run the code
To run the code you have to load the three files from the folder cleaned_datasets into a python notebook. 
After that it should be easy to run the code.
The code for the python notebook can be found in data/code or online. 
#### Data Cleaning: https://colab.research.google.com/drive/1pUzqHIlEZVbf4PpMkWufTNjrxXIGUpLD?usp=sharing
#### Data Analysis: https://colab.research.google.com/drive/1z32nFuH6E73KPNrMAsbMlHYdotzLCeBI?usp=sharing


General Information
------------------
### Author Information:
- Anna Mockenhaupt
- Matrikel No (458969)
- Thesis submitted for the degree of Medieninformatik, M.Sc.

